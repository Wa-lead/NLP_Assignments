{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification\n",
    "\n",
    "In this assignment you are required to perform text classification on App review dataset consisting of 4 classes:\n",
    "- Bug reports\n",
    "- Feature\n",
    "- Rating\n",
    "- UserExperience\n",
    "\n",
    "There are a total of 3733 samples. You need to:\n",
    "- Split the data into train/validate/test sets (70/15/15) using random seed '777' with shuffling.\n",
    "- You need to investigate issues of stop-words, infrequent words, text normalization (stemming, lemmatization, other issues of word tokenization like case normalization, punctuations). Additionally, you can also apply techniques to solve data imbalance problem. \n",
    "- You need to report appropriate measures like accuracy, precision, recall, and f1 scores (you can classification report api)\n",
    "- You should show the confusion matrix for the validation and test sets\n",
    "\n",
    "***Note:***\n",
    "- Student getting the best macro-average F1-Score receives 15% bonus grades\n",
    "- Student getting the second-best macro-average F1-Score receives 10% bonus grades\n",
    "- Student getting the third-best macro-average F1-Score receives 5% bonus grades"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read the dataset and split it into different sets\n",
    "**[20 points]** for invesitaging issues of stop-words, infrequent words, text normalization (stemming, lemmatization, other issues of word tokenization), dataset imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/AppReviews-FourClasses.csv')\n",
    "df['label'].value_counts()\n",
    "X_train = df['Review']\n",
    "y_train = df['label']\n",
    "y_train = y_train.map({'Bug': 0, 'Feature': 1, 'Rating': 2, 'UserExperience': 3})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    2461\n",
       "3     607\n",
       "0     370\n",
       "1     295\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deal with imbalance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "def oversample(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Oversamples the data using SMOTE\n",
    "    \"\"\"\n",
    "    sm = SMOTE(random_state=777)\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    y_train = pd.DataFrame(y_train)\n",
    "    return X_train, y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.3, random_state=777, stratify=y_train)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=777, stratify=y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(X: np.array):\n",
    "    X = [preprocess_sentence(x) for x in X]\n",
    "    return X\n",
    "\n",
    "def preprocess_sentence(x: str):\n",
    "    \"\"\"\n",
    "    Preprocesses a sentence\n",
    "    lower -> remove punctuation -> lemmatize\n",
    "    \"\"\"\n",
    "    # Lowercase\n",
    "    x = x.lower()\n",
    "    # Remove punctuation\n",
    "    x = x.translate(str.maketrans('', '', string.punctuation))\n",
    "    # lemmitize\n",
    "    x = x.split()\n",
    "    x = [lemmatizer.lemmatize(word) for word in x if word not in stop_words]\n",
    "    x = ' '.join(x)\n",
    "    return x\n",
    "\n",
    "X_train = preprocess(X_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Draw count distribution of words to determine threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokens = [word for sentence in X_train for word in sentence.split()]\n",
    "fdist = FreqDist(tokens)\n",
    "freq = np.array(list(fdist.values()))\n",
    "plt.hist(freq, bins=50, edgecolor='black')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Number of Words')\n",
    "plt.title('Word Frequency Distribution')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_infrequent_words(X: np.array, low_bound: int = None, up_bound: int = None, words: list = None):\n",
    "    \"\"\"\n",
    "    Removes words that are infrequent\n",
    "    \"\"\"\n",
    "    if words is None:\n",
    "        discarded_words = [word for word in fdist if fdist[word] < low_bound or fdist[word] > up_bound]\n",
    "        X = [[word for word in sentence.split() if fdist[word] >= low_bound and fdist[word] <= up_bound] for sentence in X]\n",
    "        X = [' '.join(sentence) for sentence in X]\n",
    "        return X, discarded_words\n",
    "    else:\n",
    "        X = [[word for word in sentence.split() if word not in words] for sentence in X]\n",
    "        X = [' '.join(sentence) for sentence in X]\n",
    "        return X\n",
    "\n",
    "X_train, discarded_words = remove_infrequent_words(X_train, 5, 1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. [15 points] Perform text classification using bag-of-words features\n",
    "In this part, you can use any classifier of your choice such as logistic regression or neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.2, 0.3],\n",
    "    'max_depth': [3, 4, 5, 7, 10, 15, 20, 25, 30],\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'subsample': [0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "    'colsample_bylevel': [0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "    'reg_alpha': [0, 0.001, 0.005, 0.01, 0.05],\n",
    "    'reg_lambda': [0, 0.001, 0.005, 0.01, 0.05]\n",
    "}\n",
    "\n",
    "def model_random_search(X_train, y_train, X_val, y_val, model):\n",
    "    \"\"\"\n",
    "    Trains and evaluates the model using 5-fold cross validation\n",
    "    \"\"\"\n",
    "    if type(y_train) == pd.core.frame.DataFrame:\n",
    "        if y_train.shape[1] == 1:\n",
    "            y_train = y_train['label']\n",
    "        else:\n",
    "            y_train = y_train.to_numpy()\n",
    "            \n",
    "    if type(y_val) == pd.core.frame.DataFrame:\n",
    "        if y_val.shape[1] == 1:\n",
    "            y_val = y_val['label']\n",
    "        else:\n",
    "            y_val = y_val.to_numpy()\n",
    "    \n",
    "   # Merge train and validation sets\n",
    "    X_train = np.concatenate((X_train, X_val), axis=0)\n",
    "    y_train = np.concatenate((y_train, y_val), axis=0)\n",
    "    # Train and evaluate model\n",
    "    scores = []\n",
    "    random_search = RandomizedSearchCV(model, param_grid, cv=2, n_iter=4, random_state=777, verbose=2, n_jobs=-1)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    print(\"Best parameters:\", random_search.best_params_)\n",
    "    print(\"Best cross-validation score:\", random_search.best_score_)\n",
    "    model = random_search.best_estimator_\n",
    "    return model, random_search.best_params_, random_search.best_score_\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def generate_bag_of_words(X: np.array):\n",
    "    \"\"\"\n",
    "    Generates a bag of words from the given corpus\n",
    "    \"\"\"\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(X)\n",
    "    return X, vectorizer\n",
    "\n",
    "def pca(X: np.array, explain=0.95):\n",
    "    \"\"\"\n",
    "    Performs PCA on the given data\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=explain)\n",
    "    X = pca.fit_transform(X)\n",
    "    return X, pca\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] END colsample_bylevel=0.7, colsample_bytree=0.5, learning_rate=0.3, max_depth=15, n_estimators=100, reg_alpha=0.01, reg_lambda=0.001, subsample=0.6; total time=  34.1s\n",
      "[CV] END colsample_bylevel=0.7, colsample_bytree=0.5, learning_rate=0.3, max_depth=15, n_estimators=100, reg_alpha=0.01, reg_lambda=0.001, subsample=0.6; total time=  34.3s\n",
      "[CV] END colsample_bylevel=0.8, colsample_bytree=0.9, learning_rate=0.1, max_depth=30, n_estimators=100, reg_alpha=0.05, reg_lambda=0.005, subsample=0.5; total time= 1.5min\n",
      "[CV] END colsample_bylevel=0.8, colsample_bytree=0.9, learning_rate=0.1, max_depth=30, n_estimators=100, reg_alpha=0.05, reg_lambda=0.005, subsample=0.5; total time= 1.5min\n",
      "[CV] END colsample_bylevel=0.6, colsample_bytree=0.6, learning_rate=0.1, max_depth=25, n_estimators=400, reg_alpha=0.005, reg_lambda=0.05, subsample=0.6; total time= 2.9min\n",
      "[CV] END colsample_bylevel=0.6, colsample_bytree=0.6, learning_rate=0.1, max_depth=25, n_estimators=400, reg_alpha=0.005, reg_lambda=0.05, subsample=0.6; total time= 2.9min\n",
      "[CV] END colsample_bylevel=0.9, colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=500, reg_alpha=0.01, reg_lambda=0.05, subsample=0.9; total time= 6.4min\n",
      "[CV] END colsample_bylevel=0.9, colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=500, reg_alpha=0.01, reg_lambda=0.05, subsample=0.9; total time= 6.5min\n",
      "Best parameters: {'subsample': 0.9, 'reg_lambda': 0.05, 'reg_alpha': 0.01, 'n_estimators': 500, 'max_depth': 20, 'learning_rate': 0.1, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.9}\n",
      "Best cross-validation score: 0.6099033816425121\n",
      "{'colsample_bylevel': 0.9,\n",
      " 'colsample_bytree': 0.7,\n",
      " 'learning_rate': 0.1,\n",
      " 'max_depth': 20,\n",
      " 'n_estimators': 500,\n",
      " 'reg_alpha': 0.01,\n",
      " 'reg_lambda': 0.05,\n",
      " 'subsample': 0.9}\n",
      "0.6099033816425121\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.36      0.38        55\n",
      "           1       0.16      0.22      0.18        45\n",
      "           2       0.69      0.65      0.67       369\n",
      "           3       0.17      0.19      0.18        91\n",
      "\n",
      "    accuracy                           0.51       560\n",
      "   macro avg       0.35      0.36      0.35       560\n",
      "weighted avg       0.54      0.51      0.52       560\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "X_train_bag, vectorizer = generate_bag_of_words(X_train)\n",
    "X_train_bag = X_train_bag.toarray()\n",
    "X_train_bag, y_train_bag = oversample(X_train_bag, y_train)\n",
    "# X_train_bag, pca = pca(X_train_bag)\n",
    "\n",
    "\n",
    "X_val = preprocess(X_val)\n",
    "X_val = remove_infrequent_words(X_val, words=discarded_words)\n",
    "X_val_bag = vectorizer.transform(X_val)\n",
    "X_val_bag = X_val_bag.toarray()\n",
    "# X_val_bag = pca.transform(X_val_bag)\n",
    "\n",
    "X_test = preprocess(X_test)\n",
    "X_test = remove_infrequent_words(X_test, words=discarded_words)\n",
    "X_test_bag = vectorizer.transform(X_test)\n",
    "X_test_bag = X_test_bag.toarray()\n",
    "# X_test_bag = pca.transform(X_test_bag)\n",
    "\n",
    "\n",
    "xgboost = XGBClassifier()\n",
    "xgboost, best_params, best_score = model_random_search(X_train_bag, y_train_bag, X_val_bag, y_val, xgboost)\n",
    "\n",
    "y_pred = xgboost.predict(X_test_bag)\n",
    "\n",
    "pprint(best_params)\n",
    "pprint(best_score)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. [15 points] Perform text classification using tf-idf features\n",
    "In this part, you can use any classifier of your choice such as logistic regression or neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def generate_tfidf(X: np.array):\n",
    "    \"\"\"\n",
    "    Generates a bag of words from the given corpus\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(X)\n",
    "    return X, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bylevel': 0.8,\n",
      " 'colsample_bytree': 0.9,\n",
      " 'learning_rate': 0.1,\n",
      " 'max_depth': 30,\n",
      " 'n_estimators': 100,\n",
      " 'reg_alpha': 0.05,\n",
      " 'reg_lambda': 0.005,\n",
      " 'subsample': 0.5}\n",
      "0.8625872249060655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.55      0.54        55\n",
      "           1       0.22      0.16      0.18        45\n",
      "           2       0.75      0.80      0.78       369\n",
      "           3       0.26      0.22      0.24        91\n",
      "\n",
      "    accuracy                           0.63       560\n",
      "   macro avg       0.44      0.43      0.43       560\n",
      "weighted avg       0.61      0.63      0.62       560\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_tf, vectorizer = generate_tfidf(X_train)\n",
    "X_train_tf = X_train_tf.toarray()\n",
    "X_train_tf, y_train_tf = oversample(X_train_tf, y_train)\n",
    "\n",
    "X_val = preprocess(X_val)\n",
    "X_val = remove_infrequent_words(X_val, words=discarded_words)\n",
    "X_val_tf = vectorizer.transform(X_val)\n",
    "X_val_tf = X_val_tf.toarray()\n",
    "\n",
    "X_test = preprocess(X_test)\n",
    "X_test = remove_infrequent_words(X_test, words=discarded_words)\n",
    "X_test_tf = vectorizer.transform(X_test)\n",
    "X_test_tf = X_test_tf.toarray()\n",
    "\n",
    "model = XGBClassifier()\n",
    "xgboost, best_params, best_score = model_random_search(X_train_tf, y_train_tf, X_val_tf, y_val, model)\n",
    "\n",
    "y_pred = xgboost.predict(X_test_tf)\n",
    "\n",
    "pprint(best_params)\n",
    "pprint( best_score)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. [20 points] Perform text classification using dense vectors like word2vec or Glove embeddings\n",
    "In this part, you can use any classifier of your choice such as logistic regression or neural networks. You can download and use precomputed embeddings or create your own word2vec style embeddings using libraries such as ```gensim``` (from gensim.models import Word2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "# Create Word2Vec embeddings\n",
    "sentences = [sentence.split() for sentence in X_train]\n",
    "model = gensim.models.Word2Vec(sentences, min_count=1)\n",
    "\n",
    "# Generate word embeddings\n",
    "word_embeddings = model.wv\n",
    "# Create an instance of CountVectorizer using the word embeddings\n",
    "vectorizer = CountVectorizer(vocabulary=word_embeddings.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bylevel': 0.9,\n",
      " 'colsample_bytree': 0.7,\n",
      " 'learning_rate': 0.1,\n",
      " 'max_depth': 20,\n",
      " 'n_estimators': 500,\n",
      " 'reg_alpha': 0.01,\n",
      " 'reg_lambda': 0.05,\n",
      " 'subsample': 0.9}\n",
      "0.6116478797638218\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.38      0.41        55\n",
      "           1       0.17      0.24      0.20        45\n",
      "           2       0.70      0.64      0.67       369\n",
      "           3       0.17      0.20      0.18        91\n",
      "\n",
      "    accuracy                           0.51       560\n",
      "   macro avg       0.37      0.37      0.36       560\n",
      "weighted avg       0.54      0.51      0.53       560\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate the bag-of-words feat`ures\n",
    "X_train_word = vectorizer.fit_transform(X_train)\n",
    "# Convert the features to an array\n",
    "X_train_word = X_train_word.toarray()\n",
    "X_train_word, y_train_word = oversample(X_train_word, y_train)\n",
    "\n",
    "X_val = preprocess(X_val)\n",
    "X_val = remove_infrequent_words(X_val, words=discarded_words)\n",
    "X_val_word = vectorizer.transform(X_val)\n",
    "X_val_word = X_val_word.toarray()\n",
    "\n",
    "\n",
    "X_test = preprocess(X_test)\n",
    "X_test = remove_infrequent_words(X_test, words=discarded_words)\n",
    "X_test_word = vectorizer.transform(X_test)\n",
    "X_test_word = X_test_word.toarray()\n",
    "\n",
    "model = XGBClassifier()\n",
    "xgboost, best_params, best_score = model_random_search(X_train_word, y_train_word, X_val_word, y_val, model)\n",
    "\n",
    "y_pred = xgboost.predict(X_test_word)\n",
    "\n",
    "pprint(best_params)\n",
    "pprint( best_score)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. [20 points] Perform text classification using learnt embeddings\n",
    "Here you should use RNNs. Here you need to start with random embedding vectors that will be learnt together with the main task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences, to_categorical\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "def rnn_data_pipeline(X: np.array, y: np.array, max_sequence_length: int = None):\n",
    "    \"\"\"\n",
    "    Generates the data for the RNN\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train_rnn = tokenizer.texts_to_sequences(X)\n",
    "    # Vocabulary size\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "    # Pad sequences to a fixed length\n",
    "    if max_sequence_length is None:\n",
    "        max_sequence_length = max([len(seq) for seq in X_train_rnn])\n",
    "        \n",
    "    padded_X_train_rnn = pad_sequences(X_train_rnn, maxlen=max_sequence_length)\n",
    "    # hot encode the labels\n",
    "    y_train_rnn = to_categorical(y)\n",
    "    return padded_X_train_rnn, y_train_rnn, vocab_size, max_sequence_length\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, Embedding, RNN\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Create an instance of Tokenizer\n",
    "X_train_rnn = preprocess(X_train)\n",
    "X_train_rnn = remove_infrequent_words(X_train_rnn, words=discarded_words)\n",
    "X_train_rnn , y_train_rnn, vocab_size, max_sequence_length = rnn_data_pipeline(X_train_rnn, y_train)\n",
    "X_train_rnn, y_train_rnn = oversample(X_train_rnn, y_train_rnn)\n",
    "\n",
    "X_val = preprocess(X_val)\n",
    "X_val = remove_infrequent_words(X_val, words=discarded_words)\n",
    "X_val_rnn, y_val_rnn, _, _ = rnn_data_pipeline(X_val, y_val, max_sequence_length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "431/431 [==============================] - 51s 108ms/step - loss: 0.5305 - accuracy: 0.3842 - val_loss: 0.4454 - val_accuracy: 0.5679\n",
      "Epoch 2/30\n",
      "431/431 [==============================] - 25s 57ms/step - loss: 0.4845 - accuracy: 0.4325 - val_loss: 0.4110 - val_accuracy: 0.5893\n",
      "Epoch 3/30\n",
      "431/431 [==============================] - 22s 50ms/step - loss: 0.4658 - accuracy: 0.4806 - val_loss: 0.3985 - val_accuracy: 0.6143\n",
      "Epoch 4/30\n",
      "431/431 [==============================] - 21s 48ms/step - loss: 0.4499 - accuracy: 0.5168 - val_loss: 0.3979 - val_accuracy: 0.6071\n",
      "Epoch 5/30\n",
      "431/431 [==============================] - 995s 2s/step - loss: 0.4364 - accuracy: 0.5438 - val_loss: 0.4172 - val_accuracy: 0.6000\n",
      "Epoch 6/30\n",
      "431/431 [==============================] - 1770s 4s/step - loss: 0.4213 - accuracy: 0.5749 - val_loss: 0.4083 - val_accuracy: 0.6107\n",
      "Epoch 7/30\n",
      "431/431 [==============================] - 30s 69ms/step - loss: 0.4112 - accuracy: 0.5916 - val_loss: 0.4107 - val_accuracy: 0.5857\n",
      "Epoch 8/30\n",
      "431/431 [==============================] - 18s 42ms/step - loss: 0.3986 - accuracy: 0.6104 - val_loss: 0.4112 - val_accuracy: 0.6036\n",
      "Epoch 9/30\n",
      "431/431 [==============================] - ETA: 0s - loss: 0.3900 - accuracy: 0.6281Restoring model weights from the end of the best epoch: 4.\n",
      "431/431 [==============================] - 18s 41ms/step - loss: 0.3900 - accuracy: 0.6281 - val_loss: 0.4240 - val_accuracy: 0.5857\n",
      "Epoch 9: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 32, input_length=max_sequence_length))\n",
    "model.add(LSTM(16))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n",
    "history = model.fit(X_train_rnn, y_train_rnn, epochs=30, validation_data=(X_val_rnn, y_val_rnn), batch_size=16, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 1s 48ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.44      0.50        55\n",
      "           1       0.25      0.31      0.28        45\n",
      "           2       0.84      0.74      0.79       369\n",
      "           3       0.28      0.43      0.34        91\n",
      "\n",
      "    accuracy                           0.62       560\n",
      "   macro avg       0.49      0.48      0.48       560\n",
      "weighted avg       0.68      0.62      0.64       560\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test = preprocess(X_test)\n",
    "X_test = remove_infrequent_words(X_test, words=discarded_words)\n",
    "X_test_rnn, y_test_rnn, _, _ = rnn_data_pipeline(X_test, y_test, max_sequence_length)\n",
    "y_pred = model.predict(X_test_rnn)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. [BONUS: 15 points] Perform text classification using contextual embeddings such as BERT\n",
    "Here you should use RNNs or transformers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [10 points] Document your conclusions on:\n",
    "- General conclusions about the task\n",
    "- Related to text preprocessing \n",
    "- Related to using different features/embeddings\n",
    "- Effect of different hyperparameters\n",
    "\n",
    "Write bullet points based report assuming you are presenting your conclusions to the project manager."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `General conclusions about the task`\n",
    "* The task is slightly difficult as the dataset is imbalanced and also given the large variation.\n",
    "* The solution to this is to add more data to the dataset and also to use a model that can understand the language and capture the pattern in the data.\n",
    "* However, given the aforementioned constraints, I have been able to achieve an accuracy of .61 and an F1 score of ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Related to text preprocessing`\n",
    "* Most of the time was spent on preprocessing the data correctly which will reduce and unnecessary noise in the data.\n",
    "* The applied preprocessing was the following:\n",
    "    * lowercasing\n",
    "    * removing punctuation\n",
    "    * removing stop words\n",
    "    * removing infrequent words based on a statistical analysis\n",
    "    * lemmatization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Related to using different features/embeddings`\n",
    "* Different featurizations were used for the task:\n",
    "    * Bag of words\n",
    "    * TF-IDF\n",
    "    * Word2Vec\n",
    "    * RNN -> learned embeddings\n",
    "    <br>\n",
    "    <br>\n",
    "\n",
    "* Tf-idf has performed best with Xgboost Classifier with a macro average of 0.43\n",
    "* Learned embeddings and RNN have performed the worst with a macro average of 0.48\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Effect of different hyperparameters`\n",
    "* RandomSearchCV was used to tune the hyperparameters of Xgboost Classifier and the following parameters were tuned:\n",
    "    * max_depth\n",
    "    * learning_rate\n",
    "    * n_estimators\n",
    "    * gamma\n",
    "    * min_child_weight\n",
    "    * subsample\n",
    "    * colsample_bytree\n",
    "    * reg_alpha\n",
    "    * reg_lambda\n",
    "    * scale_pos_weight\n",
    "    <br>\n",
    "    <br>\n",
    "\n",
    "* It is was observed that tuning does not help much as the the main issue was in the data.\n",
    "\n",
    "* Different Embedding sizes were tested for RNN along with different RNN neurons \n",
    "    * it was observed that 32 Embedding size and 16 RNN neurons performed the best."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
