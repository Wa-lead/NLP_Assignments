================================================================================
================================================================================
Name:
NetID:
================================================================================
================================================================================
Submission Instructions (10 points)

Make sure to follow the submission instructions as specified in the assignment.
The submission zip file should be uploaded to NYU classes.

================================================================================
================================================================================
Task 1 : Let's LM!  (10 points)
--------------------------------------------------------------------------------
Question 1.a  (1 point)  What is the effect of this tokenization step?
Describe the changes in the text.  Hint: check out nonbreaking_prefix.en.

Answer: The main purpose of tokensizer is sentence segmentation ---(complete)

--------------------------------------------------------------------------------
Question 1.b (2 points)  What is the difference between the raw and tokenized
files in terms of the number of tokens and the number of types (unique tokens)?
Explain the difference in the numbers given the used tokenization.



--------------------------------------------------------------------------------
Question 1.c  (1 point)  What is the total number of 1-gram, 2-gram and 3-gram
entries?

ngram 1=17863
ngram 2=174767
ngram 3=486802


--------------------------------------------------------------------------------
Question 1.d  (1 point)  What is the purpose of each column in the 1-grams data?

Answer: the first columns is the probability in log, while the second is the unigram itself.

--------------------------------------------------------------------------------
Question 1.e  (1 point)  Why is there no third column in the 3-grams portion?





--------------------------------------------------------------------------------
Question 1.f  (1 point)  Why is the UN LM perplexity different for the Wikipedia
and UN?



--------------------------------------------------------------------------------
Question 1.g  (1 point)  Compute the OOV rate for the UN and Wikipedia test files?
(% of OOVs/words).




--------------------------------------------------------------------------------
Question 1.h (1 point) Why is the UN LM OOV rate different for the Wikipedia and UN?




--------------------------------------------------------------------------------
Question 1.i (1 point) Provide the text you randomly generated.
How is its fluency? How is it in terms of coherence?



================================================================================
================================================================================
Task 2 : How Many Ways to LM? (40 points)

Question 2.1.a (4 points). Fill in the below table.



****************************************************************************
                           |  Words |   OOV   |  OOV%   |     ppl          |
****************************************************************************
UNCorpus.test:             |        |         |         |                  |
----------------------------------------------------------------------------
UNCorpus.test.tok:         |        |         |         |                  |
----------------------------------------------------------------------------
UNCorpus.test.tok.lc:      |        |         |         |                  |
----------------------------------------------------------------------------
UNCorpus.test.tok.lc.port: |        |         |         |                  |
----------------------------------------------------------------------------
UNCorpus.test.tok.lc.bpe:  |        |         |         |                  |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
Wiki.test:                |        |         |         |                  |
----------------------------------------------------------------------------
Wiki.test.tok:            |        |         |         |                  |
----------------------------------------------------------------------------
Wiki.test.tok.lc:         |        |         |         |                  |
 ---------------------------------------------------------------------------
Wiki.test.tok.lc.port:    |        |         |         |                  |
----------------------------------------------------------------------------
Wiki.test.tok.lc.bpe:     |        |         |         |                  |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
Fair.test:                 |        |         |         |                  |
----------------------------------------------------------------------------
Fair.test.tok:             |        |         |         |                  |
----------------------------------------------------------------------------
Fair.test.tok.lc:          |        |         |         |                  |
----------------------------------------------------------------------------
Fair.test.tok.lc.port:     |        |         |         |                  |
----------------------------------------------------------------------------
Fair.test.tok.lc.bpe:      |        |         |         |                  |
----------------------------------------------------------------------------


--------------------------------------------------------------------------------
Question 2.1.b (2 points).  What can you say about the interaction between
tokenizations and OOV rate for in-domain and out-of-domain cases?



--------------------------------------------------------------------------------
Question 2.1.c (2 points).  What can you say about the interaction between
tokenizations and perplexity?


--------------------------------------------------------------------------------
Question 2.1.d (2 points).  What do the results above suggest about the
similariy between the Wiki and UN, vs My Fair Lady and the UN?







Question 2.2.a (4 points). Fill in the below table.



*****************************************************************************
                 |  Train Size |  Words  |   OOV   |  OOV%   |     ppl      |
*****************************************************************************
UNCorpus.test    |   70000     |         |         |         |              |
-----------------------------------------------------------------------------
UNCorpus.test    |   35000     |         |         |         |              |
-----------------------------------------------------------------------------
UNCorpus.test    |   17500     |         |         |         |              |
-----------------------------------------------------------------------------
UNCorpus.test    |    8750     |         |         |         |              |
-----------------------------------------------------------------------------
UNCorpus.test    |    4375     |         |         |         |              |
-----------------------------------------------------------------------------
-----------------------------------------------------------------------------
Wiki.test:      |   70000     |         |         |         |              |
-----------------------------------------------------------------------------
Wiki.test:      |   35000     |         |         |         |              |
-----------------------------------------------------------------------------
Wiki.test:      |   17500     |         |         |         |              |
-----------------------------------------------------------------------------
Wiki.test:      |    8750     |         |         |         |              |
-----------------------------------------------------------------------------
Wiki.test:      |    4375     |         |         |         |              |
-----------------------------------------------------------------------------
-----------------------------------------------------------------------------
Fair.test:       |   70000     |         |         |         |              |
-----------------------------------------------------------------------------
Fair.test:       |   35000     |         |         |         |              |
-----------------------------------------------------------------------------
Fair.test:       |   17500     |         |         |         |              |
-----------------------------------------------------------------------------
Fair.test:       |    8750     |         |         |         |              |
-----------------------------------------------------------------------------
Fair.test:       |    4375     |         |         |         |              |
-----------------------------------------------------------------------------
-------------------------------------------------------------------------------
Question 2.2.b (2 points).  What can you say about the relationship between the
training size and OOV rate?




--------------------------------------------------------------------------------
Question 2.2.c (2 points).  What can you say about the relationship between the
training size and perplexity for in domain data?


--------------------------------------------------------------------------------
Question 2.2.d (2 points).  What can you say about the relationship between the
training size and perplexity for out-of-domain data? Is it similar or
different to in-domain data?




--------------------------------------------------------------------------------
Question 2.3.a (4 points). Fill in the below table.



*****************************************************************************
                 |             |  Words  |   OOV   |  OOV%   |     ppl      |
*****************************************************************************
UNCorpus.test    | Order 1.lm  |         |         |         |              |
-----------------------------------------------------------------------------
UNCorpus.test    | Order 2.lm  |         |         |         |              |
-----------------------------------------------------------------------------
UNCorpus.test    | Order 3.lm  |         |         |         |              |
-----------------------------------------------------------------------------
UNCorpus.test    | Order 4.lm  |         |         |         |              |
----------------------------------------------------------------------------
UNCorpus.test    | Order 5.lm  |         |         |         |              |
-----------------------------------------------------------------------------
-----------------------------------------------------------------------------
Wiki.test:      | Order 1.lm  |         |         |         |              |
-----------------------------------------------------------------------------
Wiki.test:      | Order 3.lm  |         |         |         |              |
-----------------------------------------------------------------------------
Wiki.test:      | Order 3.lm  |         |         |         |              |
-----------------------------------------------------------------------------
Wiki.test:      | Order 4.lm  |         |         |         |              |
-----------------------------------------------------------------------------
Wiki.test:      | Order 5.lm  |         |         |         |              |
-----------------------------------------------------------------------------
-----------------------------------------------------------------------------
Fair.test:       | Order 1.lm  |         |         |         |              |
-----------------------------------------------------------------------------
Fair.test:       | Order 2.lm  |         |         |         |              |
-----------------------------------------------------------------------------
Fair.test:       | Order 3.lm  |         |         |         |              |
-----------------------------------------------------------------------------
Fair.test:       | Order 4.lm  |         |         |         |              |
-----------------------------------------------------------------------------
Fair.test:       | Order 5.lm  |         |         |         |              |
-----------------------------------------------------------------------------




-------------------------------------------------------------------------------
Question 2.3.b (2 points).  What can you say about the relationship between
the LM order and OOV rate?



-------------------------------------------------------------------------------
Question 2.3.c (2 points).  What can you say about the relationship between the
LM order and perplexity for in domain data?


-------------------------------------------------------------------------------
Question 2.3.d (2 points).  What can you say about the relationship between the
LM order and perplexity for out-of-domain data?   Is it similar or different to
in-domain data?






--------------------------------------------------------------------------------
Question 2.4.a (4 points). Fill in the below table.



*****************************************************************************
                 | Smoothing   |  Words  |   OOV   |  OOV%   |     ppl      |
*****************************************************************************
UNCorpus.test    | Add 1       |         |         |         |              |
-----------------------------------------------------------------------------
UNCorpus.test    | Add 0.1     |         |         |         |              |
-----------------------------------------------------------------------------
UNCorpus.test    | Good-Turing |         |         |         |              |
-----------------------------------------------------------------------------
UNCorpus.test    | Kneser-Ney  |         |         |         |              |
-----------------------------------------------------------------------------
-----------------------------------------------------------------------------
Wiki.test:      | Add 1       |         |         |         |              |
-----------------------------------------------------------------------------
Wiki.test:      | Add 0.1     |         |         |         |              |
-----------------------------------------------------------------------------
Wiki.test:      | Good-Turing |         |         |         |              |
-----------------------------------------------------------------------------
Wiki.test:      | Kneser-Ney  |         |         |         |              |
-----------------------------------------------------------------------------
-----------------------------------------------------------------------------
Fair.test:       | Add 1       |         |         |         |              |
-----------------------------------------------------------------------------
Fair.test:       | Add 0.1     |         |         |         |              |
-----------------------------------------------------------------------------
Fair.test:       | Good-Turing |         |         |         |              |
-----------------------------------------------------------------------------
Fair.test:       | Kneser-Ney  |         |         |         |              |
-----------------------------------------------------------------------------


------------------------------------------------------------------------------
Question 2.4.b (2 points).  What can you say about the relationship between the
smoothing method and perplexity for in domain data?



-------------------------------------------------------------------------------
Question 2.4.c (2 points).  What can you say about the relationship between the
smoothing method and perplexity for out-of-domain data?
Is it similar or different to in-domain data?






--------------------------------------------------------------------------------
Question 2.4.d (2 points).  What is the best smoothing method overall?


================================================================================
================================================================================
Task 3: Guess The Language! (40 points)


1. To train on the train data and create a model directory that houses all
the .lm files:


python identify-language.py TRAIN Europarl/train/train modelxid


1. To predict the answers for the dev set and print them to STDIN/file


python identify-language.py PREDICT Europarl/dev modelxid > dev.predict


1. To evaluate the predictions against the gold


python identify-language.py EVALUATE Europarl/dev/dev.gold dev.predict



-------------------------------------------------------------------------------
Question 3.b (5 points) Modify your code to train with one line only from
training, and to use one line only from the dev files, and to use order 1
for lm.


* Run your system using this training data and report the results on the dev
set.  (1 point)



* It is reasonable to expect the accuracy to go down. Is there a pattern to
the errors?  (4 points)



--------------------------------------------------------------------------------
Question 3.c (15 points) Using your best model you have, identify the languages
of the provided test set (Europarl/test).  Provide your answer in a file named
test.pred. The file should consist of two tab separated columns marking for
each file test.<n>, its two-character language id.


test.1<tab><lang>
        test.2<tab><lang>
        ...
test.15<tab><lang>


The format should be comparable to Europarl/dev.gold.


The points for this question will be based on how many labels your system
assigns correctly.
*******************************************************************************
***********************************END*****************************************
*******************************************************************************
