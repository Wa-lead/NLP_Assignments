{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate trigam on UNCorpus, Wiki, Fair with different tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram -lm LMs/UNCorpus.train.tok.3.lm -order 3 -ppl English-Mix/UNCorpus.test\n",
      "ngram -lm LMs/UNCorpus.train.tok.3.lm -order 3 -ppl English-Mix/UNCorpus.test.tok\n",
      "ngram -lm LMs/UNCorpus.train.tok.3.lm -order 3 -ppl English-Mix/UNCorpus.test.tok.lc\n",
      "ngram -lm LMs/UNCorpus.train.tok.3.lm -order 3 -ppl English-Mix/UNCorpus.test.tok.lc.port\n",
      "ngram -lm LMs/UNCorpus.train.tok.3.lm -order 3 -ppl English-Mix/UNCorpus.test.tok.lc.bpe\n",
      "ngram -lm LMs/UNCorpus.train.tok.3.lm -order 3 -ppl English-Mix/Wiki.test\n",
      "ngram -lm LMs/UNCorpus.train.tok.3.lm -order 3 -ppl English-Mix/Wiki.test.tok\n",
      "ngram -lm LMs/UNCorpus.train.tok.3.lm -order 3 -ppl English-Mix/Wiki.test.tok.lc\n",
      "ngram -lm LMs/UNCorpus.train.tok.3.lm -order 3 -ppl English-Mix/Wiki.test.tok.lc.port\n",
      "ngram -lm LMs/UNCorpus.train.tok.3.lm -order 3 -ppl English-Mix/Wiki.test.tok.lc.bpe\n",
      "ngram -lm LMs/UNCorpus.train.tok.3.lm -order 3 -ppl English-Mix/Fair.test\n",
      "ngram -lm LMs/UNCorpus.train.tok.3.lm -order 3 -ppl English-Mix/Fair.test.tok\n",
      "ngram -lm LMs/UNCorpus.train.tok.3.lm -order 3 -ppl English-Mix/Fair.test.tok.lc\n",
      "ngram -lm LMs/UNCorpus.train.tok.3.lm -order 3 -ppl English-Mix/Fair.test.tok.lc.port\n",
      "ngram -lm LMs/UNCorpus.train.tok.3.lm -order 3 -ppl English-Mix/Fair.test.tok.lc.bpe\n"
     ]
    }
   ],
   "source": [
    "texts = ['UNCorpus', 'Wiki', 'Fair']\n",
    "tokenzations = ['test', 'test.tok', 'test.tok.lc', 'test.tok.lc.port', 'test.tok.lc.bpe']\n",
    "\n",
    "for text in texts:\n",
    "    for tokenzation in tokenzations:\n",
    "        print(f'ngram -lm LMs/UNCorpus.train.tok.3.lm -order 3 -ppl English-Mix/{text}.{tokenzation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: 4388\n",
      "OOVs: 1966\n",
      "OOV Rate: 0.45\n",
      "PPI: 2235.367\n",
      "**************************************************\n",
      "Words: 5648\n",
      "OOVs: 1761\n",
      "OOV Rate: 0.31\n",
      "PPI: 1918.732\n",
      "**************************************************\n",
      "Words: 5648\n",
      "OOVs: 1675\n",
      "OOV Rate: 0.3\n",
      "PPI: 2665.649\n",
      "**************************************************\n",
      "Words: 5648\n",
      "OOVs: 1971\n",
      "OOV Rate: 0.35\n",
      "PPI: 2210.78\n",
      "**************************************************\n",
      "Words: 8123\n",
      "OOVs: 3428\n",
      "OOV Rate: 0.42\n",
      "PPI: 3624.764\n",
      "**************************************************\n",
      "Words: []\n",
      "OOVs: []\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 52\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m50\u001b[39m)\n\u001b[1;32m     30\u001b[0m result \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\u001b[39m(base) Waleeds-MacBook-Pro:assignment2 waleedalasad$ ngram -lm LMs/UNCorpus.train.tok.3.lm -order 3 -ppl English-Mix/Fair.test\u001b[39m\n\u001b[1;32m     31\u001b[0m \u001b[39mfile English-Mix/Fair.test: 499 sentences, 4388 words, 1966 OOVs\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[39m0 zeroprobs, logprob= -9783.448 ppl= 2235.367 ppl1= 10949.86#\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \n\u001b[1;32m     50\u001b[0m \u001b[39m \u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m---> 52\u001b[0m extract_result(result\u001b[39m.\u001b[39;49msplit(\u001b[39m\"\u001b[39;49m\u001b[39m#\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "Cell \u001b[0;32mIn[8], line 26\u001b[0m, in \u001b[0;36mextract_result\u001b[0;34m(results)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mWords:\u001b[39m\u001b[39m\"\u001b[39m, words)\n\u001b[1;32m     25\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOOVs:\u001b[39m\u001b[39m\"\u001b[39m, OOVs)\n\u001b[0;32m---> 26\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOOV Rate:\u001b[39m\u001b[39m\"\u001b[39m, np\u001b[39m.\u001b[39mround(\u001b[39mint\u001b[39;49m(OOVs) \u001b[39m/\u001b[39m \u001b[39mint\u001b[39m(words),\u001b[39m2\u001b[39m))\n\u001b[1;32m     27\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPPI:\u001b[39m\u001b[39m\"\u001b[39m, PPI)\n\u001b[1;32m     28\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m50\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'list'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# define the text\n",
    "\n",
    "def extract_result(results):\n",
    "    for result in results:\n",
    "        # extract words\n",
    "        words = re.findall(r'\\d+ words', result)\n",
    "        if words:\n",
    "            words = words[0].split()[0]\n",
    "\n",
    "        # extract OOVs\n",
    "        OOVs = re.findall(r'\\d+ OOVs', result)\n",
    "        if OOVs:\n",
    "            OOVs = OOVs[0].split()[0]\n",
    "\n",
    "        # extract PPI\n",
    "        PPI = re.findall(r'ppl= (\\d+\\.\\d+)', result)\n",
    "        if PPI:\n",
    "            PPI = PPI[0]\n",
    "\n",
    "        # print the result\n",
    "        print(\"Words:\", words)\n",
    "        print(\"OOVs:\", OOVs)\n",
    "        print(\"OOV Rate:\", np.round(int(OOVs) / int(words),2))\n",
    "        print(\"PPI:\", PPI)\n",
    "        print(\"*\" * 50)\n",
    "        \n",
    "result = \"\"\"(base) Waleeds-MacBook-Pro:assignment2 waleedalasad$ ngram -lm LMs/UNCorpus.train.tok.3.lm -order 3 -ppl English-Mix/Fair.test\n",
    "file English-Mix/Fair.test: 499 sentences, 4388 words, 1966 OOVs\n",
    "0 zeroprobs, logprob= -9783.448 ppl= 2235.367 ppl1= 10949.86#\n",
    "\n",
    "(base) Waleeds-MacBook-Pro:assignment2 waleedalasad$ ngram -lm LMs/UNCorpus.train.tok.3.lm -order 3 -ppl English-Mix/Fair.test.tok\n",
    "file English-Mix/Fair.test.tok: 499 sentences, 5648 words, 1761 OOVs\n",
    "0 zeroprobs, logprob= -14399.3 ppl= 1918.732 ppl1= 5063.802#\n",
    "(base) Waleeds-MacBook-Pro:assignment2 waleedalasad$ ngram -lm LMs/UNCorpus.train.tok.3.lm -order 3 -ppl English-Mix/Fair.test.tok.lc\n",
    "ngram -lm LMs/UNCorpus.train.tok.3.lm -order 3 -ppl English-Mix/Fair.test.tok.lc.port\n",
    "ngram -lm LMs/UNCorpus.train.tok.3.lm -order 3 -ppl English-Mix/Fair.test.tok.lc.bpe\n",
    "file English-Mix/Fair.test.tok.lc: 499 sentences, 5648 words, 1675 OOVs\n",
    "0 zeroprobs, logprob= -15320.19 ppl= 2665.649 ppl1= 7179.204#\n",
    "(base) Waleeds-MacBook-Pro:assignment2 waleedalasad$ ngram -lm LMs/UNCorpus.train.tok.3.lm -order 3 -ppl English-Mix/Fair.test.tok.lc.port\n",
    "file English-Mix/Fair.test.tok.lc.port: 499 sentences, 5648 words, 1971 OOVs\n",
    "0 zeroprobs, logprob= -13966.82 ppl= 2210.78 ppl1= 6286.784#\n",
    "(base) Waleeds-MacBook-Pro:assignment2 waleedalasad$ ngram -lm LMs/UNCorpus.train.tok.3.lm -order 3 -ppl English-Mix/Fair.test.tok.lc.bpe\n",
    "file English-Mix/Fair.test.tok.lc.bpe: 499 sentences, 8123 words, 3428 OOVs\n",
    "0 zeroprobs, logprob= -18486.9 ppl= 3624.764 ppl1= 8661.073#\n",
    "(base) Waleeds-MacBook-Pro:assignment2 waleedalasad$ \n",
    "\n",
    " \"\"\"\n",
    "\n",
    "extract_result(result.split(\"#\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2.2.a\n",
    "### create models on variant subsets of data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split to 70000, 35000, 17500, 8750, 4375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'English-Mix/UNCorpus.train.tok.lc'\n",
    "sizes = [70000, 35000, 17500, 8750, 4375]\n",
    "for size in sizes:\n",
    "    with open(text, 'r') as f:\n",
    "        data = f.readlines()\n",
    "        data = data[:size]\n",
    "        with open(f'English-Mix/UNCorpus_{size}.train.tok.lc','w') as f:\n",
    "            f.writelines(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build trigram model on all splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram-count -text English-Mix/UNCorpus_70000.train.tok.lc -order 3 -lm LMs/UNCorpus_70000.train.tok.3.lm -kn-modify-counts-at-end\n",
      "ngram-count -text English-Mix/UNCorpus_35000.train.tok.lc -order 3 -lm LMs/UNCorpus_35000.train.tok.3.lm -kn-modify-counts-at-end\n",
      "ngram-count -text English-Mix/UNCorpus_17500.train.tok.lc -order 3 -lm LMs/UNCorpus_17500.train.tok.3.lm -kn-modify-counts-at-end\n",
      "ngram-count -text English-Mix/UNCorpus_8750.train.tok.lc -order 3 -lm LMs/UNCorpus_8750.train.tok.3.lm -kn-modify-counts-at-end\n",
      "ngram-count -text English-Mix/UNCorpus_4375.train.tok.lc -order 3 -lm LMs/UNCorpus_4375.train.tok.3.lm -kn-modify-counts-at-end\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for size in sizes:\n",
    "    print(f'ngram-count -text English-Mix/UNCorpus_{size}.train.tok.lc -order 3 -lm LMs/UNCorpus_{size}.train.tok.3.lm -kn-modify-counts-at-end')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UNCorpus_70000.train.tok.3.lm', 'UNCorpus_35000.train.tok.3.lm', 'UNCorpus_17500.train.tok.3.lm', 'UNCorpus_8750.train.tok.3.lm', 'UNCorpus_4375.train.tok.3.lm']\n",
      "ngram -lm LMs/UNCorpus_70000.train.tok.3.lm -order 3 -ppl English-Mix/UNCorpus.test.tok.lc\n",
      "ngram -lm LMs/UNCorpus_35000.train.tok.3.lm -order 3 -ppl English-Mix/UNCorpus.test.tok.lc\n",
      "ngram -lm LMs/UNCorpus_17500.train.tok.3.lm -order 3 -ppl English-Mix/UNCorpus.test.tok.lc\n",
      "ngram -lm LMs/UNCorpus_8750.train.tok.3.lm -order 3 -ppl English-Mix/UNCorpus.test.tok.lc\n",
      "ngram -lm LMs/UNCorpus_4375.train.tok.3.lm -order 3 -ppl English-Mix/UNCorpus.test.tok.lc\n",
      "ngram -lm LMs/UNCorpus_70000.train.tok.3.lm -order 3 -ppl English-Mix/Wiki.test.tok.lc\n",
      "ngram -lm LMs/UNCorpus_35000.train.tok.3.lm -order 3 -ppl English-Mix/Wiki.test.tok.lc\n",
      "ngram -lm LMs/UNCorpus_17500.train.tok.3.lm -order 3 -ppl English-Mix/Wiki.test.tok.lc\n",
      "ngram -lm LMs/UNCorpus_8750.train.tok.3.lm -order 3 -ppl English-Mix/Wiki.test.tok.lc\n",
      "ngram -lm LMs/UNCorpus_4375.train.tok.3.lm -order 3 -ppl English-Mix/Wiki.test.tok.lc\n",
      "ngram -lm LMs/UNCorpus_70000.train.tok.3.lm -order 3 -ppl English-Mix/Fair.test.tok.lc\n",
      "ngram -lm LMs/UNCorpus_35000.train.tok.3.lm -order 3 -ppl English-Mix/Fair.test.tok.lc\n",
      "ngram -lm LMs/UNCorpus_17500.train.tok.3.lm -order 3 -ppl English-Mix/Fair.test.tok.lc\n",
      "ngram -lm LMs/UNCorpus_8750.train.tok.3.lm -order 3 -ppl English-Mix/Fair.test.tok.lc\n",
      "ngram -lm LMs/UNCorpus_4375.train.tok.3.lm -order 3 -ppl English-Mix/Fair.test.tok.lc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "texts = ['UNCorpus.test.tok.lc','Wiki.test.tok.lc', 'Fair.test.tok.lc']\n",
    "\n",
    "# Read models in LMs\n",
    "models = os.listdir('LMs')\n",
    "models = [model for model in models if model.endswith('.lm')]\n",
    "models.remove('UNCorpus.train.tok.3.lm')\n",
    "models = sorted(models, key=lambda x: int(x.split('_')[1][:5].replace('.','')), reverse=True)\n",
    "print(models)\n",
    "for text in texts:\n",
    "    for model in models:\n",
    "        print(f'ngram -lm LMs/{model} -order 3 -ppl English-Mix/{text}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: 5648\n",
      "OOVs: 1559\n",
      "OOV Rate: 0.28\n",
      "PPI: 3741.597\n",
      "**************************************************\n",
      "Words: 5648\n",
      "OOVs: 1649\n",
      "OOV Rate: 0.29\n",
      "PPI: 2905.174\n",
      "**************************************************\n",
      "Words: 5648\n",
      "OOVs: 1812\n",
      "OOV Rate: 0.32\n",
      "PPI: 1860.581\n",
      "**************************************************\n",
      "Words: 5648\n",
      "OOVs: 1909\n",
      "OOV Rate: 0.34\n",
      "PPI: 1188.972\n",
      "**************************************************\n",
      "Words: 5648\n",
      "OOVs: 2087\n",
      "OOV Rate: 0.37\n",
      "PPI: 926.5898\n",
      "**************************************************\n",
      "Words: []\n",
      "OOVs: []\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 20\u001b[0m\n\u001b[1;32m      1\u001b[0m results \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[39m(base) Waleeds-MacBook-Pro:assignment2 waleedalasad$ ngram -lm LMs/UNCorpus_70000.train.tok.3.lm -order 3 -ppl English-Mix/Fair.test.tok.lc\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39mfile English-Mix/Fair.test.tok.lc: 499 sentences, 5648 words, 1559 OOVs\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m---> 20\u001b[0m extract_result(results\u001b[39m.\u001b[39;49msplit(\u001b[39m\"\u001b[39;49m\u001b[39m#\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m     21\u001b[0m \u001b[39m# 17500, 35000, 4375, 70000, 8750\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 26\u001b[0m, in \u001b[0;36mextract_result\u001b[0;34m(results)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mWords:\u001b[39m\u001b[39m\"\u001b[39m, words)\n\u001b[1;32m     25\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOOVs:\u001b[39m\u001b[39m\"\u001b[39m, OOVs)\n\u001b[0;32m---> 26\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOOV Rate:\u001b[39m\u001b[39m\"\u001b[39m, np\u001b[39m.\u001b[39mround(\u001b[39mint\u001b[39;49m(OOVs) \u001b[39m/\u001b[39m \u001b[39mint\u001b[39m(words),\u001b[39m2\u001b[39m))\n\u001b[1;32m     27\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPPI:\u001b[39m\u001b[39m\"\u001b[39m, PPI)\n\u001b[1;32m     28\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m50\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'list'"
     ]
    }
   ],
   "source": [
    "results = \"\"\"\n",
    "(base) Waleeds-MacBook-Pro:assignment2 waleedalasad$ ngram -lm LMs/UNCorpus_70000.train.tok.3.lm -order 3 -ppl English-Mix/Fair.test.tok.lc\n",
    "file English-Mix/Fair.test.tok.lc: 499 sentences, 5648 words, 1559 OOVs\n",
    "0 zeroprobs, logprob= -16393.19 ppl= 3741.597 ppl1= 10211.61#\n",
    "(base) Waleeds-MacBook-Pro:assignment2 waleedalasad$ ngram -lm LMs/UNCorpus_35000.train.tok.3.lm -order 3 -ppl English-Mix/Fair.test.tok.lc\n",
    "file English-Mix/Fair.test.tok.lc: 499 sentences, 5648 words, 1649 OOVs\n",
    "0 zeroprobs, logprob= -15577.35 ppl= 2905.174 ppl1= 7857.981#\n",
    "(base) Waleeds-MacBook-Pro:assignment2 waleedalasad$ ngram -lm LMs/UNCorpus_17500.train.tok.3.lm -order 3 -ppl English-Mix/Fair.test.tok.lc\n",
    "file English-Mix/Fair.test.tok.lc: 499 sentences, 5648 words, 1812 OOVs\n",
    "0 zeroprobs, logprob= -14173.93 ppl= 1860.581 ppl1= 4954.225#\n",
    "(base) Waleeds-MacBook-Pro:assignment2 waleedalasad$ ngram -lm LMs/UNCorpus_8750.train.tok.3.lm -order 3 -ppl English-Mix/Fair.test.tok.lc\n",
    "file English-Mix/Fair.test.tok.lc: 499 sentences, 5648 words, 1909 OOVs\n",
    "0 zeroprobs, logprob= -13032.58 ppl= 1188.972 ppl1= 3058.993#\n",
    "(base) Waleeds-MacBook-Pro:assignment2 waleedalasad$ ngram -lm LMs/UNCorpus_4375.train.tok.3.lm -order 3 -ppl English-Mix/Fair.test.tok.lc\n",
    "file English-Mix/Fair.test.tok.lc: 499 sentences, 5648 words, 2087 OOVs\n",
    "0 zeroprobs, logprob= -12045.56 ppl= 926.5898 ppl1= 2413.432#\n",
    "(base) Waleeds-MacBook-Pro:assignment2 waleedalasad$ \n",
    "\n",
    "\"\"\"\n",
    "extract_result(results.split(\"#\"))\n",
    "# 17500, 35000, 4375, 70000, 8750"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different order n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram-count -text English-Mix/UNCorpus.train.tok.lc -order 1 -lm LMs/nLMs/UNCorpus.train.tok.1.lm -kn-modify-counts-at-end\n",
      "ngram-count -text English-Mix/UNCorpus.train.tok.lc -order 2 -lm LMs/nLMs/UNCorpus.train.tok.2.lm -kn-modify-counts-at-end\n",
      "ngram-count -text English-Mix/UNCorpus.train.tok.lc -order 3 -lm LMs/nLMs/UNCorpus.train.tok.3.lm -kn-modify-counts-at-end\n",
      "ngram-count -text English-Mix/UNCorpus.train.tok.lc -order 4 -lm LMs/nLMs/UNCorpus.train.tok.4.lm -kn-modify-counts-at-end\n",
      "ngram-count -text English-Mix/UNCorpus.train.tok.lc -order 5 -lm LMs/nLMs/UNCorpus.train.tok.5.lm -kn-modify-counts-at-end\n"
     ]
    }
   ],
   "source": [
    "orders = [i for i in range(1, 6)]\n",
    "orders\n",
    "\n",
    "for order in orders:\n",
    "    print(f'ngram-count -text English-Mix/UNCorpus.train.tok.lc -order {order} -lm LMs/nLMs/UNCorpus.train.tok.{order}.lm -kn-modify-counts-at-end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UNCorpus.train.tok.1.lm', 'UNCorpus.train.tok.2.lm', 'UNCorpus.train.tok.3.lm', 'UNCorpus.train.tok.4.lm', 'UNCorpus.train.tok.5.lm']\n",
      "ngram -lm LMs/nLMs/UNCorpus.train.tok.1.lm -order 1 -ppl English-Mix/UNCorpus.test.tok.lc\n",
      "ngram -lm LMs/nLMs/UNCorpus.train.tok.2.lm -order 2 -ppl English-Mix/UNCorpus.test.tok.lc\n",
      "ngram -lm LMs/nLMs/UNCorpus.train.tok.3.lm -order 3 -ppl English-Mix/UNCorpus.test.tok.lc\n",
      "ngram -lm LMs/nLMs/UNCorpus.train.tok.4.lm -order 4 -ppl English-Mix/UNCorpus.test.tok.lc\n",
      "ngram -lm LMs/nLMs/UNCorpus.train.tok.5.lm -order 5 -ppl English-Mix/UNCorpus.test.tok.lc\n",
      "ngram -lm LMs/nLMs/UNCorpus.train.tok.1.lm -order 1 -ppl English-Mix/Wiki.test.tok.lc\n",
      "ngram -lm LMs/nLMs/UNCorpus.train.tok.2.lm -order 2 -ppl English-Mix/Wiki.test.tok.lc\n",
      "ngram -lm LMs/nLMs/UNCorpus.train.tok.3.lm -order 3 -ppl English-Mix/Wiki.test.tok.lc\n",
      "ngram -lm LMs/nLMs/UNCorpus.train.tok.4.lm -order 4 -ppl English-Mix/Wiki.test.tok.lc\n",
      "ngram -lm LMs/nLMs/UNCorpus.train.tok.5.lm -order 5 -ppl English-Mix/Wiki.test.tok.lc\n",
      "ngram -lm LMs/nLMs/UNCorpus.train.tok.1.lm -order 1 -ppl English-Mix/Fair.test.tok.lc\n",
      "ngram -lm LMs/nLMs/UNCorpus.train.tok.2.lm -order 2 -ppl English-Mix/Fair.test.tok.lc\n",
      "ngram -lm LMs/nLMs/UNCorpus.train.tok.3.lm -order 3 -ppl English-Mix/Fair.test.tok.lc\n",
      "ngram -lm LMs/nLMs/UNCorpus.train.tok.4.lm -order 4 -ppl English-Mix/Fair.test.tok.lc\n",
      "ngram -lm LMs/nLMs/UNCorpus.train.tok.5.lm -order 5 -ppl English-Mix/Fair.test.tok.lc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "texts = ['UNCorpus.test.tok.lc','Wiki.test.tok.lc', 'Fair.test.tok.lc']\n",
    "\n",
    "# Read models in LMs\n",
    "models = os.listdir('LMs/nLMs')\n",
    "models = [model for model in models if model.endswith('.lm')]\n",
    "models = sorted(models)\n",
    "print(models)\n",
    "for text in texts:\n",
    "    for model,order in zip(models, orders):\n",
    "        print(f'ngram -lm LMs/nLMs/{model} -order {order} -ppl English-Mix/{text}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: 5648\n",
      "OOVs: 1559\n",
      "OOV Rate: 0.28\n",
      "PPI: 1356.357\n",
      "**************************************************\n",
      "Words: 5648\n",
      "OOVs: 1559\n",
      "OOV Rate: 0.28\n",
      "PPI: 3225.199\n",
      "**************************************************\n",
      "Words: 5648\n",
      "OOVs: 1559\n",
      "OOV Rate: 0.28\n",
      "PPI: 3741.597\n",
      "**************************************************\n",
      "Words: 5648\n",
      "OOVs: 1559\n",
      "OOV Rate: 0.28\n",
      "PPI: 3768.612\n",
      "**************************************************\n",
      "Words: 5648\n",
      "OOVs: 1559\n",
      "OOV Rate: 0.28\n",
      "PPI: 3770.759\n",
      "**************************************************\n",
      "Words: []\n",
      "OOVs: []\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 20\u001b[0m\n\u001b[1;32m      1\u001b[0m results \u001b[39m=\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[39m(base) Waleeds-MacBook-Pro:assignment2 waleedalasad$ ngram -lm LMs/nLMs/UNCorpus.train.tok.1.lm -order 1 -ppl English-Mix/Fair.test.tok.lc\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39mfile English-Mix/Fair.test.tok.lc: 499 sentences, 5648 words, 1559 OOVs\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39m(base) Waleeds-MacBook-Pro:assignment2 waleedalasad$  \u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m---> 20\u001b[0m extract_result(results\u001b[39m.\u001b[39;49msplit(\u001b[39m\"\u001b[39;49m\u001b[39m#\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "Cell \u001b[0;32mIn[8], line 26\u001b[0m, in \u001b[0;36mextract_result\u001b[0;34m(results)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mWords:\u001b[39m\u001b[39m\"\u001b[39m, words)\n\u001b[1;32m     25\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOOVs:\u001b[39m\u001b[39m\"\u001b[39m, OOVs)\n\u001b[0;32m---> 26\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOOV Rate:\u001b[39m\u001b[39m\"\u001b[39m, np\u001b[39m.\u001b[39mround(\u001b[39mint\u001b[39;49m(OOVs) \u001b[39m/\u001b[39m \u001b[39mint\u001b[39m(words),\u001b[39m2\u001b[39m))\n\u001b[1;32m     27\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPPI:\u001b[39m\u001b[39m\"\u001b[39m, PPI)\n\u001b[1;32m     28\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m50\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'list'"
     ]
    }
   ],
   "source": [
    "results =\"\"\"\n",
    "(base) Waleeds-MacBook-Pro:assignment2 waleedalasad$ ngram -lm LMs/nLMs/UNCorpus.train.tok.1.lm -order 1 -ppl English-Mix/Fair.test.tok.lc\n",
    "file English-Mix/Fair.test.tok.lc: 499 sentences, 5648 words, 1559 OOVs\n",
    "0 zeroprobs, logprob= -14371.33 ppl= 1356.357 ppl1= 3270.637#\n",
    "(base) Waleeds-MacBook-Pro:assignment2 waleedalasad$ ngram -lm LMs/nLMs/UNCorpus.train.tok.2.lm -order 2 -ppl English-Mix/Fair.test.tok.lc\n",
    "file English-Mix/Fair.test.tok.lc: 499 sentences, 5648 words, 1559 OOVs\n",
    "0 zeroprobs, logprob= -16097.26 ppl= 3225.199 ppl1= 8644.151#\n",
    "(base) Waleeds-MacBook-Pro:assignment2 waleedalasad$ ngram -lm LMs/nLMs/UNCorpus.train.tok.3.lm -order 3 -ppl English-Mix/Fair.test.tok.lc\n",
    "file English-Mix/Fair.test.tok.lc: 499 sentences, 5648 words, 1559 OOVs\n",
    "0 zeroprobs, logprob= -16393.19 ppl= 3741.597 ppl1= 10211.61#\n",
    "(base) Waleeds-MacBook-Pro:assignment2 waleedalasad$ ngram -lm LMs/nLMs/UNCorpus.train.tok.4.lm -order 4 -ppl English-Mix/Fair.test.tok.lc\n",
    "file English-Mix/Fair.test.tok.lc: 499 sentences, 5648 words, 1559 OOVs\n",
    "0 zeroprobs, logprob= -16407.52 ppl= 3768.612 ppl1= 10294.37#\n",
    "(base) Waleeds-MacBook-Pro:assignment2 waleedalasad$ ngram -lm LMs/nLMs/UNCorpus.train.tok.5.lm -order 5 -ppl English-Mix/Fair.test.tok.lc\n",
    "file English-Mix/Fair.test.tok.lc: 499 sentences, 5648 words, 1559 OOVs\n",
    "0 zeroprobs, logprob= -16408.66 ppl= 3770.759 ppl1= 10300.95#\n",
    "(base) Waleeds-MacBook-Pro:assignment2 waleedalasad$  \n",
    "\"\"\"\n",
    "\n",
    "extract_result(results.split(\"#\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothened n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram-count -text English-Mix/UNCorpus.train.tok.lc -order 5 -lm LMs/smoothLMs/UNCorpus.train.tok.3.addsmooth0.1.lm -addsmooth 0.1\n",
      "ngram-count -text English-Mix/UNCorpus.train.tok.lc -order 5 -lm LMs/smoothLMs/UNCorpus.train.tok.3.addsmooth1.lm -addsmooth 1\n",
      "ngram-count -text English-Mix/UNCorpus.train.tok.lc -order 5 -lm LMs/smoothLMs/UNCorpus.train.tok.3.kndiscount.lm -kndiscount\n",
      "ngram-count -text English-Mix/UNCorpus.train.tok.lc -order 5 -lm LMs/smoothLMs/UNCorpus.train.tok.3.lm -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "smooth = ['addsmooth 0.1', 'addsmooth 1', 'kndiscount', '']\n",
    "\n",
    "for sm in smooth:\n",
    "    print(f'ngram-count -text English-Mix/UNCorpus.train.tok.lc -order 5 -lm LMs/smoothLMs/UNCorpus.train.tok.3.{sm.replace(\" \",\"\")}.lm -{sm}'.replace(\"..\",\".\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UNCorpus.train.tok.3.addsmooth0.1.lm', 'UNCorpus.train.tok.3.addsmooth1.lm', 'UNCorpus.train.tok.3.kndiscount.lm', 'UNCorpus.train.tok.3.lm']\n",
      "ngram -lm LMs/smoothLMs/UNCorpus.train.tok.3.addsmooth0.1.lm -order 5 -ppl English-Mix/UNCorpus.test.tok.lc\n",
      "ngram -lm LMs/smoothLMs/UNCorpus.train.tok.3.addsmooth1.lm -order 5 -ppl English-Mix/UNCorpus.test.tok.lc\n",
      "ngram -lm LMs/smoothLMs/UNCorpus.train.tok.3.kndiscount.lm -order 5 -ppl English-Mix/UNCorpus.test.tok.lc\n",
      "ngram -lm LMs/smoothLMs/UNCorpus.train.tok.3.lm -order 5 -ppl English-Mix/UNCorpus.test.tok.lc\n",
      "ngram -lm LMs/smoothLMs/UNCorpus.train.tok.3.addsmooth0.1.lm -order 5 -ppl English-Mix/Wiki.test.tok.lc\n",
      "ngram -lm LMs/smoothLMs/UNCorpus.train.tok.3.addsmooth1.lm -order 5 -ppl English-Mix/Wiki.test.tok.lc\n",
      "ngram -lm LMs/smoothLMs/UNCorpus.train.tok.3.kndiscount.lm -order 5 -ppl English-Mix/Wiki.test.tok.lc\n",
      "ngram -lm LMs/smoothLMs/UNCorpus.train.tok.3.lm -order 5 -ppl English-Mix/Wiki.test.tok.lc\n",
      "ngram -lm LMs/smoothLMs/UNCorpus.train.tok.3.addsmooth0.1.lm -order 5 -ppl English-Mix/Fair.test.tok.lc\n",
      "ngram -lm LMs/smoothLMs/UNCorpus.train.tok.3.addsmooth1.lm -order 5 -ppl English-Mix/Fair.test.tok.lc\n",
      "ngram -lm LMs/smoothLMs/UNCorpus.train.tok.3.kndiscount.lm -order 5 -ppl English-Mix/Fair.test.tok.lc\n",
      "ngram -lm LMs/smoothLMs/UNCorpus.train.tok.3.lm -order 5 -ppl English-Mix/Fair.test.tok.lc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "texts = ['UNCorpus.test.tok.lc','Wiki.test.tok.lc', 'Fair.test.tok.lc']\n",
    "\n",
    "# Read models in LMs\n",
    "models = os.listdir('LMs/smoothLMs')\n",
    "models = [model for model in models if model.endswith('.lm')]\n",
    "models = sorted(models)\n",
    "print(models)\n",
    "for text in texts:\n",
    "    for model in models:\n",
    "        print(f'ngram -lm LMs/smoothLMs/{model} -order 5 -ppl English-Mix/{text}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: 5648\n",
      "OOVs: 1559\n",
      "OOV Rate: 0.28\n",
      "PPI: 1819.579\n",
      "**************************************************\n",
      "Words: 5648\n",
      "OOVs: 1559\n",
      "OOV Rate: 0.28\n",
      "PPI: 1670.519\n",
      "**************************************************\n",
      "Words: 5648\n",
      "OOVs: 1559\n",
      "OOV Rate: 0.28\n",
      "PPI: 1189.075\n",
      "**************************************************\n",
      "Words: 5648\n",
      "OOVs: 1559\n",
      "OOV Rate: 0.28\n",
      "PPI: 3770.759\n",
      "**************************************************\n",
      "Words: []\n",
      "OOVs: []\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 17\u001b[0m\n\u001b[1;32m      1\u001b[0m results \u001b[39m=\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[39m(base) Waleeds-MacBook-Pro:assignment2 waleedalasad$ ngram -lm LMs/smoothLMs/UNCorpus.train.tok.3.addsmooth0.1.lm -order 5 -ppl English-Mix/Fair.test.tok.lc\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39mfile English-Mix/Fair.test.tok.lc: 499 sentences, 5648 words, 1559 OOVs\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39m(base) Waleeds-MacBook-Pro:assignment2 waleedalasad$ \u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m---> 17\u001b[0m extract_result(results\u001b[39m.\u001b[39;49msplit(\u001b[39m\"\u001b[39;49m\u001b[39m#\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "Cell \u001b[0;32mIn[8], line 26\u001b[0m, in \u001b[0;36mextract_result\u001b[0;34m(results)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mWords:\u001b[39m\u001b[39m\"\u001b[39m, words)\n\u001b[1;32m     25\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOOVs:\u001b[39m\u001b[39m\"\u001b[39m, OOVs)\n\u001b[0;32m---> 26\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOOV Rate:\u001b[39m\u001b[39m\"\u001b[39m, np\u001b[39m.\u001b[39mround(\u001b[39mint\u001b[39;49m(OOVs) \u001b[39m/\u001b[39m \u001b[39mint\u001b[39m(words),\u001b[39m2\u001b[39m))\n\u001b[1;32m     27\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPPI:\u001b[39m\u001b[39m\"\u001b[39m, PPI)\n\u001b[1;32m     28\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m50\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'list'"
     ]
    }
   ],
   "source": [
    "results =\"\"\"\n",
    "(base) Waleeds-MacBook-Pro:assignment2 waleedalasad$ ngram -lm LMs/smoothLMs/UNCorpus.train.tok.3.addsmooth0.1.lm -order 5 -ppl English-Mix/Fair.test.tok.lc\n",
    "file English-Mix/Fair.test.tok.lc: 499 sentences, 5648 words, 1559 OOVs\n",
    "0 zeroprobs, logprob= -14956.75 ppl= 1819.579 ppl1= 4547.791#\n",
    "(base) Waleeds-MacBook-Pro:assignment2 waleedalasad$ ngram -lm LMs/smoothLMs/UNCorpus.train.tok.3.addsmooth1.lm -order 5 -ppl English-Mix/Fair.test.tok.lc\n",
    "file English-Mix/Fair.test.tok.lc: 499 sentences, 5648 words, 1559 OOVs\n",
    "0 zeroprobs, logprob= -14786.44 ppl= 1670.519 ppl1= 4131.91#\n",
    "(base) Waleeds-MacBook-Pro:assignment2 waleedalasad$ ngram -lm LMs/smoothLMs/UNCorpus.train.tok.3.kndiscount.lm -order 5 -ppl English-Mix/Fair.test.tok.lc\n",
    "file English-Mix/Fair.test.tok.lc: 499 sentences, 5648 words, 1559 OOVs\n",
    "0 zeroprobs, logprob= -14109.06 ppl= 1189.075 ppl1= 2821.575#\n",
    "(base) Waleeds-MacBook-Pro:assignment2 waleedalasad$ ngram -lm LMs/smoothLMs/UNCorpus.train.tok.3.lm -order 5 -ppl English-Mix/Fair.test.tok.lc\n",
    "file English-Mix/Fair.test.tok.lc: 499 sentences, 5648 words, 1559 OOVs\n",
    "0 zeroprobs, logprob= -16408.66 ppl= 3770.759 ppl1= 10300.95#\n",
    "(base) Waleeds-MacBook-Pro:assignment2 waleedalasad$ \n",
    "\"\"\"\n",
    "\n",
    "extract_result(results.split(\"#\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
